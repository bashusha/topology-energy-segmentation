\section{Discussion and Limitations}

The proposed framework is designed as a conservative diagnostic tool rather
than as a segmentation method by default.
Structural segmentation is treated as a hypothesis that must be supported by
stable and interpretable diagnostic signals, rather than as an outcome to be
optimized or enforced.

A key feature of the diagnostics is their ability to explicitly abstain from
segmentation.
When disagreement signals are weak, unstable, or inconsistent across validation
criteria, the framework favors simpler structural explanations and returns the
global model.
This behavior is intentional and reflects uncertainty in the data rather than a
failure of the method.

As structural signals degrade, for example due to increasing noise or reduced
local sample sizes, diagnostic criteria become less decisive and energy
differences between candidate segmentations flatten.
In such regimes, the complexity penalty dominates, suppressing spurious
segmentation and reinforcing parsimony.
From a Bayesian perspective, this corresponds to posterior support remaining
concentrated on simpler structural hypotheses as the likelihood becomes less
informative.

Importantly, the framework is insensitive to uniform scale transformations of
the target variable.
Changes in magnitude alone do not induce segmentation unless they are associated
with genuine inconsistencies in conditional target behavior.
This property reflects the diagnostic focus on structural conflict in
$F \mid X$, rather than on absolute error levels.

Compared to geometry-driven clustering approaches, the proposed diagnostics are
orthogonal in spirit.
Segmentation is triggered by disagreements in predictive or distributional
behavior rather than by separation in feature space alone.
As a result, the framework can detect structurally meaningful conflicts even in
settings where geometric separation is weak or absent.

Temporal persistence, when comparable data slices are available, can be used as
an auxiliary interpretational signal.
Segmentations that are stable across time are more plausibly associated with
persistent structural obstacles, while transient or unstable zones are treated
with caution.
Temporal consistency is therefore interpreted as supportive evidence rather than
as a primary decision criterion.

\subsection{Role of the complexity penalty}

The complexity penalty parameter $\alpha$ plays a role analogous to model
selection penalties in classical statistical learning.
Rather than admitting a universally optimal choice, $\alpha$ is intended to be
used diagnostically.
Smaller values allow the framework to surface candidate structural
inconsistencies, while larger values enforce conservative behavior and favor
global explanations.

In practice, sensitivity analysis over a narrow range of $\alpha$ values,
combined with inspection of energy--complexity trade-offs and stability
considerations, provides a more informative assessment than selecting a single
fixed value.

\subsection{Computational considerations}

The framework involves several computational trade-offs.
In particular, refined disagreement measures based on rich distributional
comparisons can be computationally expensive.
For this reason, they are applied only to a restricted set of candidate
segmentations identified during the surrogate screening phase.

The use of landmarks and sparse locality graphs further reflects a deliberate
design choice to balance diagnostic sensitivity with computational feasibility.
The framework is intended primarily for offline structural assessment rather than
for real-time deployment.

\subsection{Limitations and future directions}

The proposed diagnostics require sufficient data within candidate zones to
support reliable local comparisons.
Rare regimes with very small sample sizes may remain undetectable.
The method also depends on the construction of a meaningful locality graph; poor
choices of distance metrics or neighborhood sizes can degrade diagnostic quality.

Several extensions are conceptually straightforward but are not explored in this
work.
These include richer Bayesian formulations with explicit priors over
segmentations, bootstrap-based stability assessments, and more expressive
topological diagnostics.
We leave systematic empirical evaluation of these directions for future work.
